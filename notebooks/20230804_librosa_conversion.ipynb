{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a4da02-979b-4812-ba9a-3c8025a9bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58557902-fb8e-4cf2-a4af-760beb69a652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-08-08'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output_file_date = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "output_file_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "output_file_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "099f5bd8-a949-4904-932f-6ea04f7adac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(wav_file_path):\n",
    "  y, sr = librosa.load(wav_file_path, offset=10, duration=60)\n",
    "  mfcc = np.array(librosa.feature.mfcc(y=y, sr=sr))\n",
    "  return mfcc\n",
    "    \n",
    "def get_melspectrogram(wav_file_path):\n",
    "  y, sr = librosa.load(wav_file_path, offset=10, duration=60)\n",
    "  melspectrogram = np.array(librosa.feature.melspectrogram(y=y, sr=sr))\n",
    "  return melspectrogram\n",
    "\n",
    "def get_chroma_vector(wav_file_path):\n",
    "  y, sr = librosa.load(wav_file_path)\n",
    "  chroma = np.array(librosa.feature.chroma_stft(y=y, sr=sr))\n",
    "  return chroma\n",
    "\n",
    "def get_tonnetz(wav_file_path):\n",
    "  y, sr = librosa.load(wav_file_path)\n",
    "  tonnetz = np.array(librosa.feature.tonnetz(y=y, sr=sr))\n",
    "  return tonnetz\n",
    "\n",
    "def get_feature(file_path):\n",
    "  # Extracting MFCC feature\n",
    "  mfcc = get_mfcc(file_path)\n",
    "  mfcc_mean = mfcc.mean(axis=1)\n",
    "  mfcc_min = mfcc.min(axis=1)\n",
    "  mfcc_max = mfcc.max(axis=1)\n",
    "  mfcc_feature = np.concatenate( (mfcc_mean, mfcc_min, mfcc_max) )\n",
    "\n",
    "  # Extracting Mel Spectrogram feature\n",
    "  melspectrogram = get_melspectrogram(file_path)\n",
    "  melspectrogram_mean = melspectrogram.mean(axis=1)\n",
    "  melspectrogram_min = melspectrogram.min(axis=1)\n",
    "  melspectrogram_max = melspectrogram.max(axis=1)\n",
    "  melspectrogram_feature = np.concatenate( (melspectrogram_mean, melspectrogram_min, melspectrogram_max) )\n",
    "\n",
    "  # Extracting chroma vector feature\n",
    "  chroma = get_chroma_vector(file_path)\n",
    "  chroma_mean = chroma.mean(axis=1)\n",
    "  chroma_min = chroma.min(axis=1)\n",
    "  chroma_max = chroma.max(axis=1)\n",
    "  chroma_feature = np.concatenate( (chroma_mean, chroma_min, chroma_max) )\n",
    "\n",
    "  # Extracting tonnetz feature\n",
    "  tntz = get_tonnetz(file_path)\n",
    "  tntz_mean = tntz.mean(axis=1)\n",
    "  tntz_min = tntz.min(axis=1)\n",
    "  tntz_max = tntz.max(axis=1)\n",
    "  tntz_feature = np.concatenate( (tntz_mean, tntz_min, tntz_max) ) \n",
    "  \n",
    "  feature = np.concatenate( (chroma_feature, melspectrogram_feature, mfcc_feature, tntz_feature) )\n",
    "  return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d254954b-5616-4e23-986f-ea3f5f143b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to read in Kaggle data for reverse lookup\n",
    "# IE: Once we have the song recommendations, we want to look up the information so that we can present that to the user\n",
    "kaggle = pd.read_csv(\"../data/SpotifyFeatures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "770ab9a8-1497-4dc5-bf56-a6e1123a74ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11572"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path('../data/mp3s/')\n",
    "output_dir = Path('../data/vectorized_mp3s/')\n",
    "path_glob = data_dir.rglob('*.mp3')\n",
    "file_paths = []\n",
    "for file_path in path_glob:\n",
    "    file_paths.append(file_path) # creates a list for repeated iteration\n",
    "    # if this is not done, the .rglob command above has to be repeated to regenerate iterator\n",
    "len(file_paths) # number of mp3s in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bad2cf8-d295-4d40-afe9-707fca3ba9b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for tuple in enumerate(file_paths):\n",
    "#     print(tuple) # used to find tracks that fail to convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae72e1b0-7008-41fb-bfb7-505513a52880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.144"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11572/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da8697d-4719-4591-87fb-98eed673ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Had to delete an mp3 as it was only 4 seconds long. \n",
    "# I can't explain how that happened, but the code didn't have any issue with the \n",
    "# other file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0ee0b-0a1c-4a8e-a6e0-9315ab00be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_track_ids = []\n",
    "for file_path in file_paths:\n",
    "    # print(file_path)\n",
    "    print(f'{count}. FILE PATH: \\n', f'{file_path} \\n')\n",
    "    path_split = str(file_path).split('/')\n",
    "    track_ids.append(path_split[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b13607f-cc9b-481d-9873-9f94b1d74379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_track_ids = []\n",
    "path_glob = output_dir.rglob('*.mp3')\n",
    "for file_path in path_glob:\n",
    "    # print(file_path)\n",
    "    # print(f'{count}. FILE PATH: \\n', f'{file_path} \\n')\n",
    "    path_split = str(file_path).split('/')\n",
    "    vectorized_track_ids.append(path_split[3])\n",
    "len(vectorized_track_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c219e986-c319-4aef-b98f-5bb17c061c3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. FILE PATH: \n",
      " ../data/mp3s/1ZB2qWsheGabSEYvBYxjKn/Take on Me/Weezer - Take on Me.mp3\n",
      "2. FILE PATH: \n",
      " ../data/mp3s/5V9H9J5GcUGY5ig029g5OU/Shkleepy/Manwolves - Shkleepy.mp3\n",
      "3. FILE PATH: \n",
      " ../data/mp3s/34FsCOAQ0U99vAh3uoiLmm/Bandana (feat. Young Buck)/Dirty Audio, BL3R, Young Buck - Bandana (feat. Young Buck).mp3\n",
      "4. FILE PATH: \n",
      " ../data/mp3s/25mldAmMHYzXhDXCxTpTHy/Chloroform/Phoenix - Chloroform.mp3\n",
      "5. FILE PATH: \n",
      " ../data/mp3s/1YaOBTTdptDf4vYKpFy56T/Mawaranai Toe Shoes/majiko - Mawaranai Toe Shoes.mp3\n",
      "6. FILE PATH: \n",
      " ../data/mp3s/2RbDFTlqdIdiZwO4GaTxi2/moonwalking/Good Scott - moonwalking.mp3\n",
      "7. FILE PATH: \n",
      " ../data/mp3s/2lZkIlYXN5SR0UWFgljDCd/Because You Love Me/Jo Dee Messina - Because You Love Me.mp3\n",
      "8. FILE PATH: \n",
      " ../data/mp3s/58dSdjfEYNSxte1aNVxuNf/Easy/Mac Ayres - Easy.mp3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m     count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mget_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     tracks\u001b[38;5;241m.\u001b[39mappend(array)\n\u001b[1;32m     21\u001b[0m     vectorized_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(tracks)\n",
      "Cell \u001b[0;32mIn[3], line 23\u001b[0m, in \u001b[0;36mget_feature\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_feature\u001b[39m(file_path):\n\u001b[1;32m     22\u001b[0m   \u001b[38;5;66;03m# Extracting MFCC feature\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m   mfcc \u001b[38;5;241m=\u001b[39m \u001b[43mget_mfcc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m   mfcc_mean \u001b[38;5;241m=\u001b[39m mfcc\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     25\u001b[0m   mfcc_min \u001b[38;5;241m=\u001b[39m mfcc\u001b[38;5;241m.\u001b[39mmin(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m, in \u001b[0;36mget_mfcc\u001b[0;34m(wav_file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_mfcc\u001b[39m(wav_file_path):\n\u001b[1;32m      2\u001b[0m   y, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(wav_file_path, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m   mfcc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmfcc\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m mfcc\n",
      "File \u001b[0;32m~/anaconda3/envs/brainstation_capstone/lib/python3.8/site-packages/librosa/feature/spectral.py:2002\u001b[0m, in \u001b[0;36mmfcc\u001b[0;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Mel-frequency cepstral coefficients (MFCCs)\u001b[39;00m\n\u001b[1;32m   1856\u001b[0m \n\u001b[1;32m   1857\u001b[0m \u001b[38;5;124;03m.. warning:: If multi-channel audio input ``y`` is provided, the MFCC\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[38;5;124;03m>>> fig.colorbar(img2, ax=[ax[1]])\u001b[39;00m\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m S \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2001\u001b[0m     \u001b[38;5;66;03m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[39;00m\n\u001b[0;32m-> 2002\u001b[0m     S \u001b[38;5;241m=\u001b[39m power_to_db(\u001b[43mmelspectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2004\u001b[0m M: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mfftpack\u001b[38;5;241m.\u001b[39mdct(S, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mdct_type, norm\u001b[38;5;241m=\u001b[39mnorm)[\n\u001b[1;32m   2005\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :n_mfcc, :\n\u001b[1;32m   2006\u001b[0m ]\n\u001b[1;32m   2008\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lifter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2009\u001b[0m     \u001b[38;5;66;03m# shape lifter for broadcasting\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/brainstation_capstone/lib/python3.8/site-packages/librosa/feature/spectral.py:2159\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   2156\u001b[0m \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[1;32m   2157\u001b[0m mel_basis \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mmel(sr\u001b[38;5;241m=\u001b[39msr, n_fft\u001b[38;5;241m=\u001b[39mn_fft, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 2159\u001b[0m melspec: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m...ft,mf->...mt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmel_basis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m melspec\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/brainstation_capstone/lib/python3.8/site-packages/numpy/core/einsumfunc.py:1419\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     right_pos\u001b[38;5;241m.\u001b[39mappend(input_right\u001b[38;5;241m.\u001b[39mfind(s))\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# Contract!\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m new_view \u001b[38;5;241m=\u001b[39m \u001b[43mtensordot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtmp_operands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mleft_pos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mright_pos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;66;03m# Build a new view if needed\u001b[39;00m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (tensor_result \u001b[38;5;241m!=\u001b[39m results_index) \u001b[38;5;129;01mor\u001b[39;00m handle_out:\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mtensordot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/brainstation_capstone/lib/python3.8/site-packages/numpy/core/numeric.py:1139\u001b[0m, in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes)\u001b[0m\n\u001b[1;32m   1137\u001b[0m at \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mtranspose(newaxes_a)\u001b[38;5;241m.\u001b[39mreshape(newshape_a)\n\u001b[1;32m   1138\u001b[0m bt \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mtranspose(newaxes_b)\u001b[38;5;241m.\u001b[39mreshape(newshape_b)\n\u001b[0;32m-> 1139\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mreshape(olda \u001b[38;5;241m+\u001b[39m oldb)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_paths, tracks,vectorized_track_ids = [],[],[]\n",
    "data_dir = Path('../data/mp3s/')\n",
    "output_dir = Path('../data/vectorized_mp3s/')\n",
    "downloaded_path_glob = data_dir.rglob('*.mp3')\n",
    "output_path_glob = output_dir.rglob('*.parquet')\n",
    "count = 1\n",
    "for file_path in downloaded_path_glob:\n",
    "    file_paths.append(file_path)\n",
    "for file_path in output_path_glob:\n",
    "    vectorized_track_ids.append(file_path.stem)\n",
    "for file_path in file_paths:\n",
    "    print(f'{count}. FILE PATH: \\n', f'{file_path}')\n",
    "    path_split = str(file_path).split('/')\n",
    "    track_id = path_split[3]\n",
    "    if (len(vectorized_track_ids)>0) & (track_id in vectorized_track_ids):\n",
    "        print(f'{track_id} has already been created...skipping...')\n",
    "        count+=1\n",
    "    else:\n",
    "        array = get_feature(file_path)\n",
    "        tracks.append(array)\n",
    "        vectorized_df = pd.DataFrame(tracks)\n",
    "        vectorized_df.columns = vectorized_df.columns.astype(str)\n",
    "        vectorized_df['track_id'] = track_id\n",
    "        vectorized_df.to_parquet(f\"../data/vectorized_mp3s/{track_id}.parquet\")\n",
    "        vectorized_df.to_csv(f\"../data/vectorized_mp3s/{track_id}.csv\")\n",
    "        count+=1\n",
    "    # if count % 500 == 0:\n",
    "    #     vectorized_df = pd.DataFrame(tracks, index = track_ids)\n",
    "    #     output_file_date = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    #     vectorized_df.to_parquet(f\"../data/vectorized_mp3s/{output_file_date}_vectorized_audio_data.parquet\")\n",
    "    #     vectorized_df.to_csv(f\"../data/vectorized_mp3s/{output_file_date}_vectorized_audio_data.csv\")\n",
    "    #     continue\n",
    "# vectorized_df = pd.DataFrame(tracks, index = track_ids)\n",
    "# This implementation also scales everything to 498 dimensions\n",
    "# This loop should write out every file as it moves through the data.\n",
    "# Each one will be 500 rows accept the last one which should be 73\n",
    "# This should create 24 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadfa09b-0d91-44ab-aa28-f364708fe4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1d9371-f1f0-4a80-a128-4aa41b7fda4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e3d2a-182c-4191-89a6-fcdfc616c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_df.to_parquet(f\"../data/vectorized_mp3s/{output_file_date}_vectorized_audio_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf2aa3-c21e-4282-85d0-59f512070cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_df.to_csv(f\"../data/vectorized_mp3s/{output_file_date}_vectorized_audio_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aca77ec-1f70-4d8d-9082-2882f1e8a732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e27eff-9b70-4f8c-bc32-63943b997e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a2c5027-af4d-4871-a031-0fbb43fe5f4d",
   "metadata": {},
   "source": [
    "### Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c56aa53-e979-4662-9466-1f49c5de7a14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Test to see if it could run through 5 songs\n",
    "tracks,track_ids = [], []\n",
    "count = 0\n",
    "for file_path in file_paths:\n",
    "    if count <= 4:\n",
    "        # print(file_path)\n",
    "        print('FILE PATH: \\n', f'{file_path} \\n')\n",
    "        x = str(file_path).split('/')\n",
    "        print(x)\n",
    "        track_ids.append(x[3])\n",
    "        array = get_feature(file_path)\n",
    "        tracks.append(array)\n",
    "        count+=1\n",
    "    else:\n",
    "        break\n",
    "df = pd.DataFrame(tracks, index = track_ids)\n",
    "# This implementation also scales everything to 498 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab588f9e-470b-4d8d-a21f-4e1304d25e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 498)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d532a705-37cc-48e5-9ce0-749a0630e4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.786499999999999"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assuming 9 seconds per 5 songs\n",
    "((11573/5)*9)/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d392fc04-db9f-4573-8fbf-52333dbe9be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zn/5cb91d2d665dhj_s18vtzbpc0000gn/T/ipykernel_4343/478990334.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(wav_file_path, offset=10, duration=60)\n",
      "/Users/vii/anaconda3/envs/brainstation_capstone/lib/python3.8/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=0\n",
      "  warnings.warn(\n",
      "/var/folders/zn/5cb91d2d665dhj_s18vtzbpc0000gn/T/ipykernel_4343/478990334.py:7: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(wav_file_path, offset=10, duration=60)\n"
     ]
    }
   ],
   "source": [
    "x = get_feature('../data/mp3s/3vOALqMX4c76GqWiJs3mEw/Shopping for Her Gift - Bonus Track/Alonzo Bodden - Shopping for Her Gift - Bonus Track.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4fd4aeb-d594-4a16-823e-fbe37c9a8683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f9a4c-d958-40f7-90ac-eebc767f3fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainstation_capstone",
   "language": "python",
   "name": "brainstation_capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
