{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74a4da02-979b-4812-ba9a-3c8025a9bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58557902-fb8e-4cf2-a4af-760beb69a652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-08-08'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output_file_date = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "output_file_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "output_file_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "099f5bd8-a949-4904-932f-6ea04f7adac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(wav_file_path):\n",
    "  y, sr = librosa.load(wav_file_path, offset=10, duration=60)\n",
    "  mfcc = np.array(librosa.feature.mfcc(y=y, sr=sr))\n",
    "  return mfcc\n",
    "    \n",
    "def get_melspectrogram(wav_file_path):\n",
    "  y, sr = librosa.load(wav_file_path, offset=10, duration=60)\n",
    "  melspectrogram = np.array(librosa.feature.melspectrogram(y=y, sr=sr))\n",
    "  return melspectrogram\n",
    "\n",
    "def get_chroma_vector(wav_file_path):\n",
    "  y, sr = librosa.load(wav_file_path)\n",
    "  chroma = np.array(librosa.feature.chroma_stft(y=y, sr=sr))\n",
    "  return chroma\n",
    "\n",
    "def get_tonnetz(wav_file_path):\n",
    "  y, sr = librosa.load(wav_file_path)\n",
    "  tonnetz = np.array(librosa.feature.tonnetz(y=y, sr=sr))\n",
    "  return tonnetz\n",
    "\n",
    "def get_feature(file_path):\n",
    "  # Extracting MFCC feature\n",
    "  mfcc = get_mfcc(file_path)\n",
    "  mfcc_mean = mfcc.mean(axis=1)\n",
    "  mfcc_min = mfcc.min(axis=1)\n",
    "  mfcc_max = mfcc.max(axis=1)\n",
    "  mfcc_feature = np.concatenate( (mfcc_mean, mfcc_min, mfcc_max) )\n",
    "\n",
    "  # Extracting Mel Spectrogram feature\n",
    "  melspectrogram = get_melspectrogram(file_path)\n",
    "  melspectrogram_mean = melspectrogram.mean(axis=1)\n",
    "  melspectrogram_min = melspectrogram.min(axis=1)\n",
    "  melspectrogram_max = melspectrogram.max(axis=1)\n",
    "  melspectrogram_feature = np.concatenate( (melspectrogram_mean, melspectrogram_min, melspectrogram_max) )\n",
    "\n",
    "  # Extracting chroma vector feature\n",
    "  chroma = get_chroma_vector(file_path)\n",
    "  chroma_mean = chroma.mean(axis=1)\n",
    "  chroma_min = chroma.min(axis=1)\n",
    "  chroma_max = chroma.max(axis=1)\n",
    "  chroma_feature = np.concatenate( (chroma_mean, chroma_min, chroma_max) )\n",
    "\n",
    "  # Extracting tonnetz feature\n",
    "  tntz = get_tonnetz(file_path)\n",
    "  tntz_mean = tntz.mean(axis=1)\n",
    "  tntz_min = tntz.min(axis=1)\n",
    "  tntz_max = tntz.max(axis=1)\n",
    "  tntz_feature = np.concatenate( (tntz_mean, tntz_min, tntz_max) ) \n",
    "  \n",
    "  feature = np.concatenate( (chroma_feature, melspectrogram_feature, mfcc_feature, tntz_feature) )\n",
    "  return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d254954b-5616-4e23-986f-ea3f5f143b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to read in Kaggle data for reverse lookup\n",
    "# IE: Once we have the song recommendations, we want to look up the information so that we can present that to the user\n",
    "# kaggle = pd.read_csv(\"../data/SpotifyFeatures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "770ab9a8-1497-4dc5-bf56-a6e1123a74ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11572"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path('../data/mp3s/')\n",
    "output_dir = Path('../data/vectorized_mp3s/')\n",
    "path_glob = data_dir.rglob('*.mp3')\n",
    "file_paths = []\n",
    "for file_path in path_glob:\n",
    "    file_paths.append(file_path) # creates a list for repeated iteration\n",
    "    # if this is not done, the .rglob command above has to be repeated to regenerate iterator\n",
    "len(file_paths) # number of mp3s in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bad2cf8-d295-4d40-afe9-707fca3ba9b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for tuple in enumerate(file_paths):\n",
    "#     print(tuple) # used to find tracks that fail to convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae72e1b0-7008-41fb-bfb7-505513a52880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.144"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11572/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0da8697d-4719-4591-87fb-98eed673ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Had to delete an mp3 as it was only 4 seconds long. \n",
    "# I can't explain how that happened, but the code didn't have any issue with the \n",
    "# other file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82b0ee0b-0a1c-4a8e-a6e0-9315ab00be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloaded_track_ids = []\n",
    "# for file_path in file_paths:\n",
    "#     # print(file_path)\n",
    "#     print(f'{count}. FILE PATH: \\n', f'{file_path} \\n')\n",
    "#     path_split = str(file_path).split('/')\n",
    "#     track_ids.append(path_split[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b13607f-cc9b-481d-9873-9f94b1d74379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_track_ids = []\n",
    "path_glob = output_dir.rglob('*.mp3')\n",
    "for file_path in path_glob:\n",
    "    # print(file_path)\n",
    "    # print(f'{count}. FILE PATH: \\n', f'{file_path} \\n')\n",
    "    path_split = str(file_path).split('/')\n",
    "    vectorized_track_ids.append(path_split[3])\n",
    "len(vectorized_track_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a768bd20-917e-4038-92cd-81cf263eb34e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracks = []\n",
    "data_dir = Path('../data/mp3s/')\n",
    "output_dir = Path('../data/vectorized_mp3s/')\n",
    "downloaded_path_glob = data_dir.rglob('*.mp3')\n",
    "output_path_glob = output_dir.rglob('*.parquet')\n",
    "count = 1\n",
    "file_paths = [file_path for file_path in downloaded_path_glob]\n",
    "print('Number of MP3 Files: ', len(file_paths),'\\n')\n",
    "vectorized_track_ids = [file_path.stem for file_path in output_path_glob]\n",
    "for file_path in file_paths:\n",
    "    print(f'{count}. FILE PATH: \\n', f'{file_path}')\n",
    "    path_split = str(file_path).split('/')\n",
    "    track_id = path_split[3]\n",
    "    if (len(vectorized_track_ids)>0) & (track_id in vectorized_track_ids):\n",
    "        print(f'{track_id} has already been vectorized...skipping...')\n",
    "        count+=1\n",
    "    else:\n",
    "        array = get_feature(file_path)\n",
    "        tracks.append(array)\n",
    "        vectorized_df = pd.DataFrame(tracks)\n",
    "        vectorized_df.columns = vectorized_df.columns.astype(str)\n",
    "        vectorized_df['track_id'] = track_id\n",
    "        vectorized_df.to_parquet(f\"../data/vectorized_mp3s/{track_id}.parquet\")\n",
    "        vectorized_df.to_csv(f\"../data/vectorized_mp3s/{track_id}.csv\")\n",
    "        count+=1\n",
    "    # if count % 500 == 0:\n",
    "    #     vectorized_df = pd.DataFrame(tracks, index = track_ids)\n",
    "    #     output_file_date = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    #     vectorized_df.to_parquet(f\"../data/vectorized_mp3s/{output_file_date}_vectorized_audio_data.parquet\")\n",
    "    #     vectorized_df.to_csv(f\"../data/vectorized_mp3s/{output_file_date}_vectorized_audio_data.csv\")\n",
    "    #     continue\n",
    "# vectorized_df = pd.DataFrame(tracks, index = track_ids)\n",
    "# This implementation also scales everything to 498 dimensions\n",
    "# This loop should write out every file as it moves through the data.\n",
    "# Each one will be 500 rows accept the last one which should be 73\n",
    "# This should create 24 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadfa09b-0d91-44ab-aa28-f364708fe4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1d9371-f1f0-4a80-a128-4aa41b7fda4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e3d2a-182c-4191-89a6-fcdfc616c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized_df.to_parquet(f\"../data/vectorized_mp3s/{output_file_date}_vectorized_audio_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf2aa3-c21e-4282-85d0-59f512070cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized_df.to_csv(f\"../data/vectorized_mp3s/{output_file_date}_vectorized_audio_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aca77ec-1f70-4d8d-9082-2882f1e8a732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e27eff-9b70-4f8c-bc32-63943b997e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c274243-a415-4e1c-950e-e2e2cd798eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf8fc30-0792-4fdd-bdfb-579462b29bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a2c5027-af4d-4871-a031-0fbb43fe5f4d",
   "metadata": {},
   "source": [
    "### Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c56aa53-e979-4662-9466-1f49c5de7a14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Test to see if it could run through 5 songs\n",
    "tracks,track_ids = [], []\n",
    "count = 0\n",
    "for file_path in file_paths:\n",
    "    if count <= 4:\n",
    "        # print(file_path)\n",
    "        print('FILE PATH: \\n', f'{file_path} \\n')\n",
    "        x = str(file_path).split('/')\n",
    "        print(x)\n",
    "        track_ids.append(x[3])\n",
    "        array = get_feature(file_path)\n",
    "        tracks.append(array)\n",
    "        count+=1\n",
    "    else:\n",
    "        break\n",
    "df = pd.DataFrame(tracks, index = track_ids)\n",
    "# This implementation also scales everything to 498 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab588f9e-470b-4d8d-a21f-4e1304d25e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 498)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d532a705-37cc-48e5-9ce0-749a0630e4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.786499999999999"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assuming 9 seconds per 5 songs\n",
    "((11573/5)*9)/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d392fc04-db9f-4573-8fbf-52333dbe9be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zn/5cb91d2d665dhj_s18vtzbpc0000gn/T/ipykernel_4343/478990334.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(wav_file_path, offset=10, duration=60)\n",
      "/Users/vii/anaconda3/envs/brainstation_capstone/lib/python3.8/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=0\n",
      "  warnings.warn(\n",
      "/var/folders/zn/5cb91d2d665dhj_s18vtzbpc0000gn/T/ipykernel_4343/478990334.py:7: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(wav_file_path, offset=10, duration=60)\n"
     ]
    }
   ],
   "source": [
    "x = get_feature('../data/mp3s/3vOALqMX4c76GqWiJs3mEw/Shopping for Her Gift - Bonus Track/Alonzo Bodden - Shopping for Her Gift - Bonus Track.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4fd4aeb-d594-4a16-823e-fbe37c9a8683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f9a4c-d958-40f7-90ac-eebc767f3fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainstation_capstone",
   "language": "python",
   "name": "brainstation_capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
